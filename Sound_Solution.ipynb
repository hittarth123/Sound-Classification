{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code block imports necessary libraries and modules for audio feature extraction, CNN model creation, and data preprocessing. It includes:\n",
        "\n",
        "os: for operating system-related functionalities.\n",
        "\n",
        "pandas: for ease of operating on arrays\n",
        "\n",
        "librosa: for audio feature extraction. \n",
        "\n",
        "numpy: for numerical operations.\n",
        "\n",
        "StratifiedKFold from sklearn.model_selection: for splitting data into train and test sets while maintaining class balance.\n",
        "\n",
        "Sequential, Conv2D, MaxPooling2D, Flatten, Dense, Dropout from tensorflow.keras.layers: for building the CNN model architecture.\n",
        "\n",
        "to_categorical from tensorflow.keras.utils: for converting class labels to categorical format.\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "This block sets up the initial environment and imports necessary tools for the subsequent cod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYJy3oaqqIft"
      },
      "outputs": [],
      "source": [
        "# Imports and Setup\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"\\\\UrbanSound8K\\\\audio\" #Insert the base path here\n",
        "\n",
        "# Path to the metadata CSV file\n",
        "metadata_file = \"\\\\UrbanSound8K.csv\" #Insert the metadata file path that contains the output answers here\n",
        "\n",
        "# Number of cross-validation folds, do not change\n",
        "n_folds = 10\n",
        "\n",
        "# Input shape for the CNN model (assuming grayscale images for the sounds)\n",
        "input_shape = (256, 256, 1)\n",
        "\n",
        "# Determine the number of classes in the dataset\n",
        "metadata = pd.read_csv(metadata_file)\n",
        "num_classes = metadata['class'].nunique()\n",
        "\n",
        "# Batch size for training\n",
        "batch_size = 64\n",
        "\n",
        "# Number of epochs for training the model\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBDSZQJVqIfv"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store audio file paths and corresponding labels\n",
        "audio_paths = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over each folder in the base path\n",
        "for folder in sorted(os.listdir(base_path)):\n",
        "    # Construct full path to the current folder\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    \n",
        "    # Check if the current item in the directory is a folder\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Iterate over each file in the current folder\n",
        "        for file in os.listdir(folder_path):\n",
        "            # Construct full path to the current file\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            \n",
        "            # Check if the file is a WAV audio file\n",
        "            if file.endswith('.wav'):\n",
        "                # Append the file path to the list of audio paths\n",
        "                audio_paths.append(file_path)\n",
        "                \n",
        "                # Append the folder name (label) to the list of labels\n",
        "                labels.append(folder)\n",
        "\n",
        "# Convert the lists to NumPy arrays for convenience\n",
        "audio_paths = np.array(audio_paths)\n",
        "labels = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM8A58RyqIfw"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path, metadata, n_mels=256, hop_length=1024, n_fft=4096):\n",
        "    \"\"\"\n",
        "    Extracts Mel spectrogram features from an audio file.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path: Path to the audio file.\n",
        "    - metadata: DataFrame containing metadata information.\n",
        "    - n_mels: Number of Mel frequency bins.\n",
        "    - hop_length: Number of samples between successive frames.\n",
        "    - n_fft: Number of samples used for each Fourier transform.\n",
        "\n",
        "    Returns:\n",
        "    - mel_spec_db: Mel spectrogram feature with added channel dimension.\n",
        "    - label: Label corresponding to the audio file.\n",
        "    \"\"\"\n",
        "    # Extract file name from file path\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "    # Retrieve metadata row corresponding to the file name\n",
        "    row = metadata[metadata['slice_file_name'] == file_name]\n",
        "\n",
        "    # Check if the metadata row is empty (i.e., file not found in metadata)\n",
        "    if row.empty:\n",
        "        return None, None  \n",
        "\n",
        "    # Extract label from metadata\n",
        "    label = row['classID'].values[0]\n",
        "\n",
        "    # Load audio file using librosa\n",
        "    audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
        "\n",
        "    # Compute Mel spectrogram\n",
        "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "\n",
        "    # Convert to decibels (dB)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    # Resize spectrogram to fixed length (input_shape[0])\n",
        "    mel_spec_db = librosa.util.fix_length(mel_spec_db, size=input_shape[0], axis=1)\n",
        "\n",
        "    # Add channel dimension to spectrogram\n",
        "    mel_spec_db = mel_spec_db.reshape((*input_shape[:2], 1))\n",
        "\n",
        "    return mel_spec_db, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Creation\n",
        "def create_cnn_model(num_classes):\n",
        "    \"\"\"\n",
        "    Creates a Convolutional Neural Network (CNN) model for classification.\n",
        "    \n",
        "    Parameters:\n",
        "    - num_classes: Number of classes for classification.\n",
        "    \n",
        "    Returns:\n",
        "    - model: CNN model compiled with specified optimizer, loss function, and metrics.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyYym35PqIfx"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store extracted features and corresponding labels\n",
        "X_features = []\n",
        "y_labels = []\n",
        "\n",
        "# Iterate over each audio file path\n",
        "for file_path in audio_paths:\n",
        "    # Extract features and label for the current audio file\n",
        "    features, label = extract_features(file_path, metadata)\n",
        "    \n",
        "    # Check if features are successfully extracted (not None)\n",
        "    if features is not None:\n",
        "        # Append extracted features to the list of X_features\n",
        "        X_features.append(features)\n",
        "        \n",
        "        # Append corresponding label to the list of y_labels\n",
        "        y_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays for convenience\n",
        "X_features = np.array(X_features)\n",
        "y_labels = np.array(y_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ShI5I9qIfx"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=False)\n",
        "accuracy_scores = []\n",
        "\n",
        "# Iterate over each fold in the cross-validation\n",
        "for fold_idx, (train_index, test_index) in enumerate(skf.split(X_features, y_labels)):\n",
        "    # Split features and labels into training and testing sets\n",
        "    X_train_features, X_test_features = X_features[train_index], X_features[test_index]\n",
        "    y_train, y_test = y_labels[train_index], y_labels[test_index]\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "    # Create and compile the CNN model\n",
        "    model = create_cnn_model(num_classes)\n",
        "    \n",
        "    # Train the CNN model on the training data\n",
        "    model.fit(X_train_features, y_train_cat, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "    # Evaluate the model on test data and collect accuracy\n",
        "    _, test_accuracy = model.evaluate(X_test_features, y_test_cat, verbose=0)\n",
        "    accuracy_scores.append(test_accuracy)\n",
        "\n",
        "    # Print the test accuracy for the current fold\n",
        "    print(f\"Fold {fold_idx + 1}: Test Accuracy = {test_accuracy}\")\n",
        "\n",
        "# Calculate and print average accuracy and standard deviation\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_dev = np.std(accuracy_scores)\n",
        "print(f\"Average Accuracy: {mean_accuracy:.4f} Â± {std_dev:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
